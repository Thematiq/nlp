{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP - lab2\n",
    "\n",
    "### Mateusz Praski\n",
    "\n",
    "---\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:40.944068Z",
     "start_time": "2023-10-22T10:34:40.503318Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from glob import glob\n",
    "from tqdm import trange, tqdm\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3 & 4\n",
    "Define an ES analyzer for Polish texts containing:\n",
    "- standard tokenizer\n",
    "- synonym filter with alternative forms for months, e.g. wrzesień, wrz, IX.\n",
    "- lowercase filter\n",
    "- Morfologik-based lemmatizer\n",
    "- lowercase filter (looks strange, but Morfologi produces capitalized base forms for proper names, so we have to lowercase them once more).\n",
    "\n",
    "Define another analyzer for Polish, without the synonym filter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "analyzer_with_synonyms = {\n",
    "    'type': 'custom',\n",
    "    'tokenizer': 'standard',\n",
    "    'filter': [\n",
    "        'months-synonyms',\n",
    "        'lowercase',\n",
    "        'morfologik_stem',\n",
    "        'lowercase'\n",
    "    ]\n",
    "}\n",
    "\n",
    "analyzer_without_synonyms = {\n",
    "    'type': 'custom',\n",
    "    'tokenizer': 'standard',\n",
    "    'filter': [\n",
    "        'lowercase',\n",
    "        'morfologik_stem',\n",
    "        'lowercase'\n",
    "    ]\n",
    "}\n",
    "\n",
    "no_lemma_synonyms = {\n",
    "    'type': 'custom',\n",
    "    'tokenizer': 'standard',\n",
    "    'filter': [\n",
    "        'months-synonyms',\n",
    "        'lowercase',\n",
    "    ]\n",
    "}\n",
    "\n",
    "no_lemma_no_synonyms = {\n",
    "    'type': 'custom',\n",
    "    'tokenizer': 'standard',\n",
    "    'filter': [\n",
    "        'lowercase',\n",
    "    ]\n",
    "}\n",
    "\n",
    "filters = {\n",
    "    'months-synonyms': {\n",
    "        'type': 'synonym',\n",
    "        'synonyms': [\n",
    "            'sty, I => styczeń',\n",
    "            'lut, II => luty',\n",
    "            'mar, III => marzec',\n",
    "            'kwi, IV => kwiecień',\n",
    "            'V => maj',\n",
    "            'cze, VI => czerwiec',\n",
    "            'lip, VII => lipca',\n",
    "            'sie, VIII => sierpnia',\n",
    "            'wrz, IX => wrzesień',\n",
    "            'paz, X => pażdziernik',\n",
    "            'lis, XI => listopad',\n",
    "            'gru, XII => grudzień'\n",
    "        ]\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:40.950012Z",
     "start_time": "2023-10-22T10:34:40.945331Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 5\n",
    "\n",
    "Define an ES index for storing the contents of the corpus from lab 1 using both analyzers. Use different names for the fields analyzed with a different pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "index_definition = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'answer': {\n",
    "                'type': 'text',\n",
    "                'fields': {\n",
    "                    'with_synonyms': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'analyze_with_synonyms'\n",
    "                    },\n",
    "                    'without_synonyms': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'analyze_without_synonyms'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    'settings': {\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'analyze_with_synonyms': analyzer_with_synonyms,\n",
    "                'analyze_without_synonyms': analyzer_without_synonyms,\n",
    "                'analyze_no_lemma_synonyms': no_lemma_synonyms,\n",
    "                'analyze_no_lemma_no_synonyms': no_lemma_no_synonyms\n",
    "            },\n",
    "            'filter': filters\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:40.957755Z",
     "start_time": "2023-10-22T10:34:40.955135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"mappings\": {\n",
      "        \"properties\": {\n",
      "            \"answer\": {\n",
      "                \"type\": \"text\",\n",
      "                \"fields\": {\n",
      "                    \"with_synonyms\": {\n",
      "                        \"type\": \"text\",\n",
      "                        \"analyzer\": \"analyze_with_synonyms\"\n",
      "                    },\n",
      "                    \"without_synonyms\": {\n",
      "                        \"type\": \"text\",\n",
      "                        \"analyzer\": \"analyze_without_synonyms\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"settings\": {\n",
      "        \"analysis\": {\n",
      "            \"analyzer\": {\n",
      "                \"analyze_with_synonyms\": {\n",
      "                    \"type\": \"custom\",\n",
      "                    \"tokenizer\": \"standard\",\n",
      "                    \"filter\": [\n",
      "                        \"months-synonyms\",\n",
      "                        \"lowercase\",\n",
      "                        \"morfologik_stem\",\n",
      "                        \"lowercase\"\n",
      "                    ]\n",
      "                },\n",
      "                \"analyze_without_synonyms\": {\n",
      "                    \"type\": \"custom\",\n",
      "                    \"tokenizer\": \"standard\",\n",
      "                    \"filter\": [\n",
      "                        \"lowercase\",\n",
      "                        \"morfologik_stem\",\n",
      "                        \"lowercase\"\n",
      "                    ]\n",
      "                },\n",
      "                \"analyze_no_lemma_synonyms\": {\n",
      "                    \"type\": \"custom\",\n",
      "                    \"tokenizer\": \"standard\",\n",
      "                    \"filter\": [\n",
      "                        \"months-synonyms\",\n",
      "                        \"lowercase\"\n",
      "                    ]\n",
      "                },\n",
      "                \"analyze_no_lemma_no_synonyms\": {\n",
      "                    \"type\": \"custom\",\n",
      "                    \"tokenizer\": \"standard\",\n",
      "                    \"filter\": [\n",
      "                        \"lowercase\"\n",
      "                    ]\n",
      "                }\n",
      "            },\n",
      "            \"filter\": {\n",
      "                \"months-synonyms\": {\n",
      "                    \"type\": \"synonym\",\n",
      "                    \"synonyms\": [\n",
      "                        \"sty, I => stycze\\u0144\",\n",
      "                        \"lut, II => luty\",\n",
      "                        \"mar, III => marzec\",\n",
      "                        \"kwi, IV => kwiecie\\u0144\",\n",
      "                        \"V => maj\",\n",
      "                        \"cze, VI => czerwiec\",\n",
      "                        \"lip, VII => lipca\",\n",
      "                        \"sie, VIII => sierpnia\",\n",
      "                        \"wrz, IX => wrzesie\\u0144\",\n",
      "                        \"paz, X => pa\\u017cdziernik\",\n",
      "                        \"lis, XI => listopad\",\n",
      "                        \"gru, XII => grudzie\\u0144\"\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "body = json.dumps(index_definition, indent=4)\n",
    "print(body)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:40.965844Z",
     "start_time": "2023-10-22T10:34:40.960342Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[H\u001B[2J\u001B[?25l\u001B[?7l\u001B[0m\u001B[31m\u001B[1m                     ./\u001B[0m\u001B[35m\u001B[1mo\u001B[0m\u001B[34m\u001B[1m.\r\n",
      "\u001B[0m\u001B[31m\u001B[1m                   ./\u001B[0m\u001B[35m\u001B[1msssso\u001B[0m\u001B[34m\u001B[1m-\r\n",
      "\u001B[0m\u001B[31m\u001B[1m                 `:\u001B[0m\u001B[35m\u001B[1mosssssss+\u001B[0m\u001B[34m\u001B[1m-\r\n",
      "\u001B[0m\u001B[31m\u001B[1m               `:+\u001B[0m\u001B[35m\u001B[1msssssssssso\u001B[0m\u001B[34m\u001B[1m/.\r\n",
      "\u001B[0m\u001B[31m\u001B[1m             `-/o\u001B[0m\u001B[35m\u001B[1mssssssssssssso\u001B[0m\u001B[34m\u001B[1m/.\r\n",
      "\u001B[0m\u001B[31m\u001B[1m           `-/+\u001B[0m\u001B[35m\u001B[1msssssssssssssssso\u001B[0m\u001B[34m\u001B[1m+:`\r\n",
      "\u001B[0m\u001B[31m\u001B[1m         `-:/+\u001B[0m\u001B[35m\u001B[1msssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m+/.\r\n",
      "\u001B[0m\u001B[31m\u001B[1m       `.://o\u001B[0m\u001B[35m\u001B[1msssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m++-\r\n",
      "\u001B[0m\u001B[31m\u001B[1m      .://+\u001B[0m\u001B[35m\u001B[1mssssssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m++:\r\n",
      "\u001B[0m\u001B[31m\u001B[1m    .:///o\u001B[0m\u001B[35m\u001B[1mssssssssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m++:\r\n",
      "\u001B[0m\u001B[31m\u001B[1m  `:////\u001B[0m\u001B[35m\u001B[1mssssssssssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m+++.\r\n",
      "\u001B[0m\u001B[31m\u001B[1m`-////+\u001B[0m\u001B[35m\u001B[1mssssssssssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m++++-\r\n",
      "\u001B[0m\u001B[31m\u001B[1m `..-+\u001B[0m\u001B[35m\u001B[1moosssssssssssssssssssssssso\u001B[0m\u001B[34m\u001B[1m+++++/`\r\n",
      "   ./++++++++++++++++++++++++++++++/:.\r\n",
      "  `:::::::::::::::::::::::::------``\u001B[0m\r\n",
      "\u001B[15A\u001B[9999999D\u001B[43C\u001B[0m\u001B[1m\u001B[31m\u001B[1mthmtt\u001B[0m@\u001B[31m\u001B[1mmsi-linux\u001B[0m \r\n",
      "\u001B[43C\u001B[0m---------------\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mOS\u001B[0m\u001B[0m:\u001B[0m EndeavourOS Linux x86_64\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mHost\u001B[0m\u001B[0m:\u001B[0m B660M DS3H DDR4\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mKernel\u001B[0m\u001B[0m:\u001B[0m 6.5.5-arch1-1\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mUptime\u001B[0m\u001B[0m:\u001B[0m 24 mins\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mPackages\u001B[0m\u001B[0m:\u001B[0m 1361 (pacman)\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mShell\u001B[0m\u001B[0m:\u001B[0m fish 3.6.1\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mResolution\u001B[0m\u001B[0m:\u001B[0m 1920x1080, 1920x1080\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mDE\u001B[0m\u001B[0m:\u001B[0m Plasma 5.27.8\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mWM\u001B[0m\u001B[0m:\u001B[0m KWin\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mTheme\u001B[0m\u001B[0m:\u001B[0m [Plasma], Breeze [GTK2/3]\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mIcons\u001B[0m\u001B[0m:\u001B[0m [Plasma], WhiteSur-dark [GTK2/3]\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mCPU\u001B[0m\u001B[0m:\u001B[0m 12th Gen Intel i5-12400 (12) @ 4.400GHz\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mGPU\u001B[0m\u001B[0m:\u001B[0m NVIDIA GeForce RTX 3070 Ti\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mGPU\u001B[0m\u001B[0m:\u001B[0m Intel Alder Lake-S GT1 [UHD Graphics 730]\u001B[0m \r\n",
      "\u001B[43C\u001B[0m\u001B[35m\u001B[1mMemory\u001B[0m\u001B[0m:\u001B[0m 8514MiB / 31875MiB\u001B[0m \r\n",
      "\r\n",
      "\u001B[43C\u001B[30m\u001B[40m   \u001B[31m\u001B[41m   \u001B[32m\u001B[42m   \u001B[33m\u001B[43m   \u001B[34m\u001B[44m   \u001B[35m\u001B[45m   \u001B[36m\u001B[46m   \u001B[37m\u001B[47m   \u001B[m\r\n",
      "\u001B[43C\u001B[38;5;8m\u001B[48;5;8m   \u001B[38;5;9m\u001B[48;5;9m   \u001B[38;5;10m\u001B[48;5;10m   \u001B[38;5;11m\u001B[48;5;11m   \u001B[38;5;12m\u001B[48;5;12m   \u001B[38;5;13m\u001B[48;5;13m   \u001B[38;5;14m\u001B[48;5;14m   \u001B[38;5;15m\u001B[48;5;15m   \u001B[m\r\n",
      "\r\n",
      "\r\n",
      "\u001B[?25h\u001B[?7h\u001B[sPreparing to copy...\u001B[?25l\u001B[u\u001B[2KCopying from container - 0B\u001B[?25h\u001B[u\u001B[2KSuccessfully copied 3.58kB to /home/thmtt/AGH/masters/semester-2/nlp/labs/lab2/.\r\n"
     ]
    }
   ],
   "source": [
    "!docker cp elastic_container:/usr/share/elasticsearch/config/certs/http_ca.crt ."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:43.765890Z",
     "start_time": "2023-10-22T10:34:41.557202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ELASTIC_IP = 'https://localhost:9200'\n",
    "INDEX = 'nlp-index'\n",
    "auth = ('elastic', '\"qwerty\"')\n",
    "cert = 'http_ca.crt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:46.659166Z",
     "start_time": "2023-10-22T10:34:46.650150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(200, None)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.delete(f'{ELASTIC_IP}/{INDEX}', auth=auth, verify=cert)\n",
    "res.status_code, print(res.content.decode())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:47.939572Z",
     "start_time": "2023-10-22T10:34:47.482787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"nlp-index\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(200, None)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.put(f'{ELASTIC_IP}/{INDEX}', json=index_definition, auth=auth, verify=cert)\n",
    "res.status_code, print(res.content.decode())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:54.687835Z",
     "start_time": "2023-10-22T10:34:54.449757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    title                                               text metadata\n_id                                                                  \n3          Nie mówię, że nie podoba mi się też pomysł szk...       {}\n31         Tak więc nic nie zapobiega fałszywym ocenom po...       {}\n56         Nigdy nie możesz korzystać z FSA dla indywidua...       {}\n59         Samsung stworzył LCD i inne technologie płaski...       {}\n63         Oto wymagania SEC: Federalne przepisy dotycząc...       {}",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>metadata</th>\n    </tr>\n    <tr>\n      <th>_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td></td>\n      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td></td>\n      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td></td>\n      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td></td>\n      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../../data/corpus.jsonl\", lines=True)\n",
    "df = df.set_index('_id').sort_index()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:34:58.107298Z",
     "start_time": "2023-10-22T10:34:56.967451Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 6\n",
    "\n",
    "Load the data to the ES index."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def bulk_insert(rows, col):\n",
    "    n = len(rows)\n",
    "    request_command = [f'{{\"index\": {{ \"_index\": \"{INDEX}\" }} }}'] * n\n",
    "    request_data = [f'{{\"with_synonyms\": {text}, \"without_synonyms\": {text}}}' for text in rows]\n",
    "\n",
    "    payload = [None] * (n * 2)\n",
    "    payload[::2] = request_command\n",
    "    payload[1::2] = request_data\n",
    "    body = \"\\n\".join(payload) + '\\n'\n",
    "    print(body)\n",
    "    # Didn't work  in the end :(\n",
    "    res = requests.post(f'{ELASTIC_IP}/_bulk?pretty', data=body, headers={'Content-type': 'application/x-ndjson'}, auth=auth, verify=cert)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:47:07.677451Z",
     "start_time": "2023-10-22T10:47:07.669079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def standard_insert(df, disable_tqdm=False):\n",
    "    for index, row in tqdm(df.iterrows(), disable=disable_tqdm, total=len(df.index)):\n",
    "        rs = requests.put(f\"{ELASTIC_IP}/{INDEX}/_doc/{index}\", json={\"answer\": row['text']}, auth=auth, verify=cert)\n",
    "        if rs.status_code != 201 and rs.status_code != 200:\n",
    "            raise RuntimeError(f\"{rs.status_code} - {rs.text}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# res = requests.post(f\"{ELASTIC_IP}/{INDEX}/_doc\", json={\"text\": text}, auth=auth, verify=cert)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:50:42.332707Z",
     "start_time": "2023-10-22T10:50:42.175673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# res.status_code"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T10:50:42.722651Z",
     "start_time": "2023-10-22T10:50:42.719160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57638/57638 [12:39<00:00, 75.94it/s]\n"
     ]
    }
   ],
   "source": [
    "standard_insert(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "'{\"count\":57638,\"_shards\":{\"total\":1,\"successful\":1,\"skipped\":0,\"failed\":0}}'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(f\"{ELASTIC_IP}/{INDEX}/_count\", auth=auth, verify=cert).text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "res = requests.get(f\"{ELASTIC_IP}/{INDEX}/_search?pretty&size=5\", auth=auth, verify=cert, json={\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": df.iloc[0]['text'],\n",
    "            \"fields\": [\n",
    "                \"answer.with_synonyms\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def query_text(text, analyzer=None, limit=None, use_synonyms=True):\n",
    "    url = f\"{ELASTIC_IP}/{INDEX}/_search\"\n",
    "    if limit is not None:\n",
    "        url += f\"?size={limit}\"\n",
    "\n",
    "    index = \"answer.with_synonyms\" if use_synonyms else \"answer.without_synonyms\"\n",
    "\n",
    "    body  = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                index: {\n",
    "                    \"query\": text,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if analyzer is not None:\n",
    "        body[\"query\"][\"match\"][index][\"analyzer\"]  = analyzer\n",
    "\n",
    "    rs = requests.get(url, json=body, auth=auth, verify=cert)\n",
    "    if rs.status_code != 200:\n",
    "        raise RuntimeError(f\"{rs.status_code} - {rs.text}\")\n",
    "    return json.loads(rs.text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 7\n",
    "\n",
    "Determine the number of documents containing the word `styczeń` (in any form) including and excluding the synonyms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With synonyms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "3101"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text(\"styczeń\")['hits']['total']['value']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Without synonyms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "329"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text(\"styczeń\", use_synonyms=False)['hits']['total']['value']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's worth mentioning that synonym for `styczeń` is  `I`, which may occur in some other texts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'_index': 'nlp-index',\n '_id': '71552',\n '_score': 5.8238015,\n '_source': {'answer': 'Niech P oznacza kwotę inwestycji, R stopę zwrotu, a I stopę inflacji. Dla uproszczenia załóżmy, że płatność p jest dokonywana corocznie zaraz po uzyskaniu zwrotu. Tak więc, na koniec roku, inwestycja P wzrosła do P*(1+R), a p jest zwracane jako wypłata renty. Jeżeli I = 0, cały zwrot może zostać wypłacony jako zapłata, a więc p = P*R. Oznacza to, że pod koniec roku, gdy kurz opadnie po odebraniu zwrotu P*R i wypłaceniu go jako renty dożywotniej, P jest ponownie dostępne na początku następnego roku, aby zarobić zwrot według stawki R. My mieć P*(1+R) - p = P Jeżeli I > 0, to na koniec roku, po opadnięciu kurzu, nie możemy sobie pozwolić na posiadanie tylko P jako inwestycji na przyszły rok. Przyszłoroczna opłata musi wynosić p*(1+I), więc potrzebujemy większej inwestycji, ponieważ stopa zwrotu jest stała. O ile większy? Cóż, jeśli inwestycja na początku przyszłego roku wyniesie P*(1+I), zarobi dokładnie tyle dodatkowych pieniędzy, aby wypłacić podwyższoną opłatę na następny rok, a pozostało wystarczająco dużo, aby pomóc w przyszłych podwyżkach płatności. (Zauważ, że zakładamy, że R > I. Jeśli R < I, nie można utworzyć wieczystego majątku.) Załóżmy zatem, że wybieramy p takie, że P*(1+R) - p = P*(1+I) Mnożenie to równanie przez (1+I), mamy [P(1+I)]*(1+R) - [p*(1+I)] = P*(1+I)^2 Słowem, w na początku przyszłego roku inwestycja wynosi P*(1+I), a zwrot pomniejszony o zwiększoną wypłatę p*(1+I) pozostawia inwestycję w wysokości P*(1+I)^2 na kolejny rok. Każdego roku wpłata i kwota do zainwestowania na kolejny rok wzrasta o współczynnik (1+I). Rozwiązując P*(1+R) - p = P*(1+I) dla p, otrzymujemy p = P*(R-I) jako początkową spłatę wieczystą, a wypłata wzrasta o czynnik (1+I) każdego roku. Inwestycja początkowa wynosi P i również wzrasta o współczynnik (1+I) każdego roku. W późniejszych latach inwestycja to P*(1+I)^n na początku roku, płatność to p*(1+I)^n a kwota zainwestowana na kolejny rok to P*(1+I )^{n+1}. Jest to ten sam wynik, jaki uzyskał PO, ale napisany w sposób, który mogę zrozumieć, to znaczy bez finansowego żargonu o stopach dyskontowych, gradientach, PV, FV i tym podobnych.'}}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text(\"styczeń\")['hits']['hits'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 9\n",
    "Compute NDCG@5 for the QA dataset (the test subset) for the following setups\n",
    "- synonyms enabled and disabled,\n",
    "- lemmatization in the query enabled and disabled."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   _id                                               text metadata\n0    0  Co jest uważane za wydatek służbowy w podróży ...       {}\n1    4  Wydatki służbowe - ubezpieczenie samochodu pod...       {}\n2    5                  Rozpoczęcie nowego biznesu online       {}\n3    6     „Dzień roboczy” i „termin płatności” rachunków       {}\n4    7  Nowy właściciel firmy – Jak działają podatki d...       {}",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>text</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>Rozpoczęcie nowego biznesu online</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>„Dzień roboczy” i „termin płatności” rachunków</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>Nowy właściciel firmy – Jak działają podatki d...</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.read_json('../../data/queries.jsonl', lines=True)\n",
    "questions.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   query-id  corpus-id  score\n0         0      18850      1\n0         1      14255      1\n1         2     308938      1\n2         3     296717      1\n3         3     100764      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query-id</th>\n      <th>corpus-id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>18850</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14255</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>308938</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>296717</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>100764</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pd.concat([\n",
    "    pd.read_csv(path, sep='\\t')\n",
    "    for path in glob('../../data/*.tsv')\n",
    "])\n",
    "qa = qa.sort_values(by='query-id')\n",
    "qa.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa['score'].nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "qa_mapping = csr_matrix(\n",
    "    (qa['score'], (qa['query-id'], qa['corpus-id'])),\n",
    "    shape=(qa['query-id'].max() + 1, df.index.max() + 1),\n",
    "    dtype=int\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_mapping[1, 2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "query-id\n0        1\n1        1\n2        1\n3        4\n4        1\n        ..\n11092    6\n11096    4\n11097    1\n11099    2\n11104    1\nName: count, Length: 6648, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_matches = qa.groupby('query-id')['corpus-id'].count().rename('count')\n",
    "max_matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def eval_answers(questions, analyzer, use_syonynms):\n",
    "    no_questions = len(questions.index)\n",
    "    rec = np.empty((no_questions, 5), dtype=int)\n",
    "\n",
    "    for index, row in tqdm(questions.iterrows(), total=no_questions):\n",
    "        rs = query_text(row['text'], analyzer=analyzer, limit=5, use_synonyms=use_syonynms)\n",
    "\n",
    "        recs = [qa_mapping[int(row['_id']), int(rs['_id'])] for rs in rs['hits']['hits'][:5]]\n",
    "        if len(recs) < 5:\n",
    "            recs += [-1] * (5 - len(recs))\n",
    "\n",
    "        rec[index] = recs\n",
    "    return rec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [01:55<00:00, 57.67it/s]\n"
     ]
    }
   ],
   "source": [
    "rec_lemma_synonyms = eval_answers(questions, 'analyze_with_synonyms', use_syonynms=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [01:56<00:00, 57.08it/s]\n"
     ]
    }
   ],
   "source": [
    "rec_lemma_no_synonyms = eval_answers(questions, 'analyze_without_synonyms', use_syonynms=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [01:37<00:00, 68.12it/s]\n"
     ]
    }
   ],
   "source": [
    "rec_no_lemma_synonyms = eval_answers(questions, 'analyze_no_lemma_synonyms', use_syonynms=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [01:34<00:00, 70.15it/s]\n"
     ]
    }
   ],
   "source": [
    "rec_no_lemma_no_synonyms = eval_answers(questions, 'analyze_no_lemma_no_synonyms', use_syonynms=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6648it [00:00, 30445.81it/s]\n"
     ]
    }
   ],
   "source": [
    "perfect_answers = np.zeros((len(questions.index), 5), dtype=int)\n",
    "\n",
    "for index, row in tqdm(questions.iterrows()):\n",
    "    matches = min(max_matches.loc[row['_id']], 5)\n",
    "    vector = ([1] * matches) + ([0] * (5 - matches))\n",
    "    perfect_answers[index, :] = vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    'rs/scores.npz',\n",
    "    no_lemma_no_synonyms=rec_no_lemma_no_synonyms,\n",
    "    no_lemma_synonyms=rec_no_lemma_synonyms,\n",
    "    lemma_no_synonyms=rec_lemma_no_synonyms,\n",
    "    lemma_synonyms=rec_lemma_synonyms\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "            lemmatization no_lemmatization\nsynonyms           77.08%           75.34%\nno_synonyms        77.09%           75.34%",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lemmatization</th>\n      <th>no_lemmatization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>synonyms</th>\n      <td>77.08%</td>\n      <td>75.34%</td>\n    </tr>\n    <tr>\n      <th>no_synonyms</th>\n      <td>77.09%</td>\n      <td>75.34%</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={\n",
    "    \"lemmatization\": [\n",
    "        ndcg_score(perfect_answers, rec_lemma_synonyms),\n",
    "        ndcg_score(perfect_answers, rec_lemma_no_synonyms)\n",
    "    ],\n",
    "    \"no_lemmatization\": [\n",
    "        ndcg_score(perfect_answers, rec_no_lemma_synonyms),\n",
    "        ndcg_score(perfect_answers, rec_no_lemma_no_synonyms)\n",
    "    ]},\n",
    "    index=[\"synonyms\", \"no_synonyms\"]\n",
    ").applymap(lambda x: f\"{x:.2%}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
